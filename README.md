# This page is dedicated to all pruning related papers. 


## Pruning Survey Paper - To Read

| Survey Paper              | Backlog | Reading | Notes-Composed | 
| ------------------------  |---------| --------| ---------------|
|[Neural Network Pruning 101](https://towardsdatascience.com/neural-network-pruning-101-af816aaea61)|:white_check_mark: |:white_check_mark:||
|[Methods for pruning deep neiral networks](http://usir.salford.ac.uk/id/eprint/64107/8/Methods_for_Pruning_Deep_Neural_Networks.pdf)| :white_check_mark: |||
|[Pruning Algorithms - A Survey](https://axon.cs.byu.edu/~martinez/classes/678/Papers/Reed_PruningSurvey.pdf)|:white_check_mark: ||| 
|[Convolutional Neural Network Pruning: A Survey](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9189610)|:white_check_mark: |||
|[WHAT IS THE STATE OF NEURAL NETWORK PRUNING?](https://arxiv.org/pdf/2003.03033.pdf)|:white_check_mark: |||
|[A Survey of Model Compression and Acceleration for Deep Neural Networks](https://arxiv.org/abs/1710.09282)| :white_check_mark: |||
|[Pruning Algorithms to Accelerate Convolutional Neural Networks for Edge Applications: A Survey](https://arxiv.org/pdf/2005.04275.pdf)| :white_check_mark: |||


## Pruning Paper - The Lottery Ticket Hypothesis 

| Paper               | Backlog | Reading | Notes-Composed | 
| --------------------|---------| --------| ---------------|
| [Deep Compression: Pruning + Quantization + Huffman Coding](https://arxiv.org/abs/1510.00149) |:white_check_mark: |:white_check_mark:||
| [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks](https://arxiv.org/abs/1803.03635)|:white_check_mark: |:white_check_mark:||
| [Dual Lottery Ticket Hypothesis](https://openreview.net/forum?id=fOsN52jn25l)|:white_check_mark: |:white_check_mark:||
| [Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot?](https://papers.nips.cc/paper/2021/hash/6a130f1dc6f0c829f874e92e5458dced-Abstract.html)|:white_check_mark: |:white_check_mark:||
| [One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers](https://arxiv.org/abs/1906.02773)|:white_check_mark: |:white_check_mark:||
| [Winning the Lottery Ahead of Time: Efficient Early Network Pruning](https://proceedings.mlr.press/v162/rachwan22a.html) |:white_check_mark: |||
| [On Lottery Tickets and Minimal Task Representations in Deep Reinforcement Learning](https://openreview.net/forum?id=Fl3Mg_MZR-)|:white_check_mark: |||
| [Revisit Kernel Pruning with Lottery Regulated Grouped Convolutions](https://openreview.net/forum?id=LdEhiMG9WLO)|:white_check_mark: |||
| [Proving the Lottery Ticket Hypothesis for Convolutional Neural Networks](https://openreview.net/forum?id=Vjki79-619-)|:white_check_mark: |||
| [On the Existence of Universal Lottery Tickets ](https://openreview.net/forum?id=SYB4WrJql1n)|:white_check_mark: |||
| [Validating the Lottery Ticket Hypothesis with Inertial Manifold Theory](https://papers.nips.cc/paper/2021/hash/fdc42b6b0ee16a2f866281508ef56730-Abstract.html)|:white_check_mark: |||
| [The Elastic Lottery Ticket Hypothesis](https://papers.nips.cc/paper/2021/hash/dfccdb8b1cc7e4dab6d33db0fef12b88-Abstract.html)|:white_check_mark: |||
| [Why Lottery Ticket Wins? A Theoretical Perspective of Sample Complexity on Sparse Neural Networks](https://papers.nips.cc/paper/2021/hash/15f99f2165aa8c86c9dface16fefd281-Abstract.html)|:white_check_mark: |||
| [Pruning Randomly Initialized Neural Networks with Iterative Randomization](https://papers.nips.cc/paper/2021/hash/23e582ad8087f2c03a5a31c125123f9a-Abstract.html)|:white_check_mark: |||
| [Multi-Prize Lottery Ticket Hypothesis: Finding Accurate Binary Neural Networks by Pruning A Randomly Weighted Network](https://openreview.net/forum?id=U_mat0b9iv)|:white_check_mark: |||
| [Proving the Lottery Ticket Hypothesis: Pruning is All You Need](https://arxiv.org/abs/2002.00585)|:white_check_mark: |||
| [Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask](https://arxiv.org/abs/1905.01067)|:white_check_mark: |||


## The Lottery Ticket Hypothesis - Extended (Transformers)
| Paper              | Backlog | Reading | Notes-Composed|
| -------------------|---------|---------|---------------|
| [The Lottery Ticket Hypothesis for Pre-trained BERT Networks](https://proceedings.neurips.cc/paper/2020/file/b6af2c9703f203a2794be03d443af2e3-Paper.pdf)|:white_check_mark: |||
| [Dissecting Lottery Ticket Transformers: Structural and Behavioral Study of Sparse Neural Machine Translation](https://aclanthology.org/2020.blackboxnlp-1.19/)|:white_check_mark: |||


